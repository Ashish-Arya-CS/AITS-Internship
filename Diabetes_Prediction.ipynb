{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Diabetes Prediction\n",
    "Diabetes is a serious problem which many people face nowadays and which can lead to other serious health diseases.During the period of Covid-19 we also came to know that the conditions of a diabetic patient is much more critical than a non-diabetic patient.So if we can take help of deep learning to predict the risk of getting diabetic it will be helpful for people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imorting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:09.854852Z",
     "iopub.status.busy": "2020-11-20T01:08:09.854525Z",
     "iopub.status.idle": "2020-11-20T01:08:10.249119Z",
     "shell.execute_reply": "2020-11-20T01:08:10.248103Z",
     "shell.execute_reply.started": "2020-11-20T01:08:09.854817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-20 01:08:09--  https://cainvas-static.s3.amazonaws.com/media/user_data/arya.ashish/diabetes.zip\n",
      "Resolving cainvas-static.s3.amazonaws.com (cainvas-static.s3.amazonaws.com)... 52.219.62.68\n",
      "Connecting to cainvas-static.s3.amazonaws.com (cainvas-static.s3.amazonaws.com)|52.219.62.68|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12371 (12K) [application/x-zip-compressed]\n",
      "Saving to: ‘diabetes.zip’\n",
      "\n",
      "diabetes.zip        100%[===================>]  12.08K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-11-20 01:08:09 (120 MB/s) - ‘diabetes.zip’ saved [12371/12371]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -N \"https://cainvas-static.s3.amazonaws.com/media/user_data/arya.ashish/diabetes.zip\"\n",
    "!unzip -qo diabetes.zip \n",
    "!rm diabetes.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_active": false,
    "_cell_guid": "67610f18-83ae-28d9-c866-519c8cb1a0cb",
    "_execution_state": "idle",
    "_uuid": "5f929632417d7741183b994ec93ad79c275e016e",
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:10.251369Z",
     "iopub.status.busy": "2020-11-20T01:08:10.250830Z",
     "iopub.status.idle": "2020-11-20T01:08:12.257245Z",
     "shell.execute_reply": "2020-11-20T01:08:12.256083Z",
     "shell.execute_reply.started": "2020-11-20T01:08:10.251328Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.260518Z",
     "iopub.status.busy": "2020-11-20T01:08:12.259714Z",
     "iopub.status.idle": "2020-11-20T01:08:12.296829Z",
     "shell.execute_reply": "2020-11-20T01:08:12.295807Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.260453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            2      138             62             35        0  33.6   \n",
       "1            0       84             82             31      125  38.2   \n",
       "2            0      145              0              0        0  44.2   \n",
       "3            0      135             68             42      250  42.3   \n",
       "4            1      139             62             41      480  40.7   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.127   47        1  \n",
       "1                     0.233   23        0  \n",
       "2                     0.630   31        1  \n",
       "3                     0.365   24        1  \n",
       "4                     0.536   21        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.299238Z",
     "iopub.status.busy": "2020-11-20T01:08:12.298627Z",
     "iopub.status.idle": "2020-11-20T01:08:12.323098Z",
     "shell.execute_reply": "2020-11-20T01:08:12.322011Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.299190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               2000 non-null   int64  \n",
      " 1   Glucose                   2000 non-null   int64  \n",
      " 2   BloodPressure             2000 non-null   int64  \n",
      " 3   SkinThickness             2000 non-null   int64  \n",
      " 4   Insulin                   2000 non-null   int64  \n",
      " 5   BMI                       2000 non-null   float64\n",
      " 6   DiabetesPedigreeFunction  2000 non-null   float64\n",
      " 7   Age                       2000 non-null   int64  \n",
      " 8   Outcome                   2000 non-null   int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 140.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.325508Z",
     "iopub.status.busy": "2020-11-20T01:08:12.324795Z",
     "iopub.status.idle": "2020-11-20T01:08:12.342228Z",
     "shell.execute_reply": "2020-11-20T01:08:12.341109Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.325455Z"
    }
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.344383Z",
     "iopub.status.busy": "2020-11-20T01:08:12.343690Z",
     "iopub.status.idle": "2020-11-20T01:08:12.365314Z",
     "shell.execute_reply": "2020-11-20T01:08:12.364343Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.344338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 744 entries, 0 to 1568\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               744 non-null    int64  \n",
      " 1   Glucose                   744 non-null    int64  \n",
      " 2   BloodPressure             744 non-null    int64  \n",
      " 3   SkinThickness             744 non-null    int64  \n",
      " 4   Insulin                   744 non-null    int64  \n",
      " 5   BMI                       744 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  744 non-null    float64\n",
      " 7   Age                       744 non-null    int64  \n",
      " 8   Outcome                   744 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 58.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.367505Z",
     "iopub.status.busy": "2020-11-20T01:08:12.366777Z",
     "iopub.status.idle": "2020-11-20T01:08:12.393158Z",
     "shell.execute_reply": "2020-11-20T01:08:12.392013Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.367450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 744 entries, 0 to 1568\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               744 non-null    int64  \n",
      " 1   Glucose                   739 non-null    float64\n",
      " 2   BloodPressure             710 non-null    float64\n",
      " 3   SkinThickness             529 non-null    float64\n",
      " 4   Insulin                   385 non-null    float64\n",
      " 5   BMI                       734 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  744 non-null    float64\n",
      " 7   Age                       744 non-null    int64  \n",
      " 8   Outcome                   744 non-null    int64  \n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 58.1 KB\n"
     ]
    }
   ],
   "source": [
    "columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "for col in columns:\n",
    "    df[col].replace(0, np.NaN, inplace=True)\n",
    "    \n",
    "df.info()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.395427Z",
     "iopub.status.busy": "2020-11-20T01:08:12.394774Z",
     "iopub.status.idle": "2020-11-20T01:08:12.418068Z",
     "shell.execute_reply": "2020-11-20T01:08:12.417059Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.395379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 381 entries, 1 to 1567\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               381 non-null    int64  \n",
      " 1   Glucose                   381 non-null    float64\n",
      " 2   BloodPressure             381 non-null    float64\n",
      " 3   SkinThickness             381 non-null    float64\n",
      " 4   Insulin                   381 non-null    float64\n",
      " 5   BMI                       381 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  381 non-null    float64\n",
      " 7   Age                       381 non-null    int64  \n",
      " 8   Outcome                   381 non-null    int64  \n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 29.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_active": false,
    "_cell_guid": "9d4e8dae-2820-cde6-b603-b9d4bdb2acc7",
    "_execution_state": "idle",
    "_uuid": "797cf71e5a2f2a5e93fee78eb4f07e1c0bcc816d",
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.422345Z",
     "iopub.status.busy": "2020-11-20T01:08:12.421584Z",
     "iopub.status.idle": "2020-11-20T01:08:12.438487Z",
     "shell.execute_reply": "2020-11-20T01:08:12.436850Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.422287Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', axis=1)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_active": false,
    "_cell_guid": "ee011c74-d139-b96b-28e3-5b19a625f423",
    "_execution_state": "idle",
    "_uuid": "5a9f32468c5b24fb5e021ea6c43531aa3e15e86a",
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.441461Z",
     "iopub.status.busy": "2020-11-20T01:08:12.440644Z",
     "iopub.status.idle": "2020-11-20T01:08:12.448373Z",
     "shell.execute_reply": "2020-11-20T01:08:12.447287Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.441402Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "ad34ae6d2a8a7926ba41caf16e786752f1a4120c",
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.450819Z",
     "iopub.status.busy": "2020-11-20T01:08:12.450082Z",
     "iopub.status.idle": "2020-11-20T01:08:12.458539Z",
     "shell.execute_reply": "2020-11-20T01:08:12.457173Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.450776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((304, 8), (77, 8), (304,), (77,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.467137Z",
     "iopub.status.busy": "2020-11-20T01:08:12.466361Z",
     "iopub.status.idle": "2020-11-20T01:08:12.573087Z",
     "shell.execute_reply": "2020-11-20T01:08:12.572120Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.467093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 185\n",
      "Trainable params: 185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, activation = 'relu', input_shape = X_train[0].shape))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(Dense(4, activation='relu')) \n",
    "\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.575267Z",
     "iopub.status.busy": "2020-11-20T01:08:12.574601Z",
     "iopub.status.idle": "2020-11-20T01:08:12.598185Z",
     "shell.execute_reply": "2020-11-20T01:08:12.597042Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.575224Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer= opt ,loss='binary_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:08:12.600935Z",
     "iopub.status.busy": "2020-11-20T01:08:12.600119Z",
     "iopub.status.idle": "2020-11-20T01:09:08.312254Z",
     "shell.execute_reply": "2020-11-20T01:09:08.305066Z",
     "shell.execute_reply.started": "2020-11-20T01:08:12.600873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      " 9/19 [=============>................] - ETA: 0s - loss: 0.6813 - acc: 0.6250\n",
      "Epoch 00001: val_acc improved from -inf to 0.67532, saving model to diabetes.h5\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.6786 - acc: 0.6546 - val_loss: 0.6746 - val_acc: 0.6753\n",
      "Epoch 2/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6791 - acc: 0.6875\n",
      "Epoch 00002: val_acc improved from 0.67532 to 0.71429, saving model to diabetes.h5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6764 - acc: 0.6579 - val_loss: 0.6724 - val_acc: 0.7143\n",
      "Epoch 3/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6822 - acc: 0.6250\n",
      "Epoch 00003: val_acc improved from 0.71429 to 0.72727, saving model to diabetes.h5\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6742 - acc: 0.6579 - val_loss: 0.6699 - val_acc: 0.7273\n",
      "Epoch 4/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6989 - acc: 0.3750\n",
      "Epoch 00004: val_acc improved from 0.72727 to 0.74026, saving model to diabetes.h5\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6719 - acc: 0.6546 - val_loss: 0.6676 - val_acc: 0.7403\n",
      "Epoch 5/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6702 - acc: 0.6507\n",
      "Epoch 00005: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6697 - acc: 0.6612 - val_loss: 0.6650 - val_acc: 0.7403\n",
      "Epoch 6/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6671 - acc: 0.6667\n",
      "Epoch 00006: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6672 - acc: 0.6612 - val_loss: 0.6625 - val_acc: 0.7403\n",
      "Epoch 7/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6656 - acc: 0.6701\n",
      "Epoch 00007: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.6648 - acc: 0.6612 - val_loss: 0.6599 - val_acc: 0.7403\n",
      "Epoch 8/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6576 - acc: 0.8125\n",
      "Epoch 00008: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6624 - acc: 0.6645 - val_loss: 0.6573 - val_acc: 0.7403\n",
      "Epoch 9/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6580 - acc: 0.6250\n",
      "Epoch 00009: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6599 - acc: 0.6645 - val_loss: 0.6546 - val_acc: 0.7403\n",
      "Epoch 10/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6899 - acc: 0.5625\n",
      "Epoch 00010: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6575 - acc: 0.6645 - val_loss: 0.6518 - val_acc: 0.7403\n",
      "Epoch 11/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.6499 - acc: 0.6615\n",
      "Epoch 00011: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.6551 - acc: 0.6645 - val_loss: 0.6491 - val_acc: 0.7403\n",
      "Epoch 12/350\n",
      "10/19 [==============>...............] - ETA: 0s - loss: 0.6550 - acc: 0.6687\n",
      "Epoch 00012: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6525 - acc: 0.6645 - val_loss: 0.6464 - val_acc: 0.7403\n",
      "Epoch 13/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6606 - acc: 0.5625\n",
      "Epoch 00013: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6501 - acc: 0.6645 - val_loss: 0.6436 - val_acc: 0.7403\n",
      "Epoch 14/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6606 - acc: 0.5625\n",
      "Epoch 00014: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6476 - acc: 0.6645 - val_loss: 0.6407 - val_acc: 0.7403\n",
      "Epoch 15/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6334 - acc: 0.6875\n",
      "Epoch 00015: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6452 - acc: 0.6645 - val_loss: 0.6375 - val_acc: 0.7403\n",
      "Epoch 16/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.6473 - acc: 0.6615\n",
      "Epoch 00016: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6425 - acc: 0.6645 - val_loss: 0.6346 - val_acc: 0.7403\n",
      "Epoch 17/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6482 - acc: 0.6250\n",
      "Epoch 00017: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6400 - acc: 0.6645 - val_loss: 0.6317 - val_acc: 0.7403\n",
      "Epoch 18/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5839 - acc: 0.8125\n",
      "Epoch 00018: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6375 - acc: 0.6645 - val_loss: 0.6287 - val_acc: 0.7403\n",
      "Epoch 19/350\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.6342 - acc: 0.6786\n",
      "Epoch 00019: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.6351 - acc: 0.6645 - val_loss: 0.6255 - val_acc: 0.7403\n",
      "Epoch 20/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6740 - acc: 0.6250\n",
      "Epoch 00020: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6327 - acc: 0.6645 - val_loss: 0.6223 - val_acc: 0.7403\n",
      "Epoch 21/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5391 - acc: 0.8750\n",
      "Epoch 00021: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6302 - acc: 0.6645 - val_loss: 0.6190 - val_acc: 0.7403\n",
      "Epoch 22/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6622 - acc: 0.6875\n",
      "Epoch 00022: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6276 - acc: 0.6645 - val_loss: 0.6159 - val_acc: 0.7403\n",
      "Epoch 23/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5966 - acc: 0.8125\n",
      "Epoch 00023: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6251 - acc: 0.6645 - val_loss: 0.6127 - val_acc: 0.7403\n",
      "Epoch 24/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6558 - acc: 0.5000\n",
      "Epoch 00024: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6225 - acc: 0.6645 - val_loss: 0.6096 - val_acc: 0.7403\n",
      "Epoch 25/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6208 - acc: 0.6562\n",
      "Epoch 00025: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6199 - acc: 0.6645 - val_loss: 0.6065 - val_acc: 0.7403\n",
      "Epoch 26/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6091 - acc: 0.6250\n",
      "Epoch 00026: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6174 - acc: 0.6645 - val_loss: 0.6033 - val_acc: 0.7403\n",
      "Epoch 27/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6527 - acc: 0.4375\n",
      "Epoch 00027: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6147 - acc: 0.6645 - val_loss: 0.6003 - val_acc: 0.7403\n",
      "Epoch 28/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5857 - acc: 0.8125\n",
      "Epoch 00028: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6123 - acc: 0.6645 - val_loss: 0.5970 - val_acc: 0.7403\n",
      "Epoch 29/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6565 - acc: 0.6250\n",
      "Epoch 00029: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6097 - acc: 0.6645 - val_loss: 0.5940 - val_acc: 0.7403\n",
      "Epoch 30/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6353 - acc: 0.6875\n",
      "Epoch 00030: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.6072 - acc: 0.6645 - val_loss: 0.5909 - val_acc: 0.7403\n",
      "Epoch 31/350\n",
      "10/19 [==============>...............] - ETA: 0s - loss: 0.6123 - acc: 0.6562\n",
      "Epoch 00031: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.6044 - acc: 0.6645 - val_loss: 0.5878 - val_acc: 0.7403\n",
      "Epoch 32/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5811 - acc: 0.8125\n",
      "Epoch 00032: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6017 - acc: 0.6645 - val_loss: 0.5847 - val_acc: 0.7403\n",
      "Epoch 33/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6569 - acc: 0.5000\n",
      "Epoch 00033: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5991 - acc: 0.6645 - val_loss: 0.5814 - val_acc: 0.7403\n",
      "Epoch 34/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6049 - acc: 0.6875\n",
      "Epoch 00034: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5965 - acc: 0.6645 - val_loss: 0.5780 - val_acc: 0.7403\n",
      "Epoch 35/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6012 - acc: 0.6875\n",
      "Epoch 00035: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5939 - acc: 0.6645 - val_loss: 0.5746 - val_acc: 0.7403\n",
      "Epoch 36/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6176 - acc: 0.6875\n",
      "Epoch 00036: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5914 - acc: 0.6645 - val_loss: 0.5710 - val_acc: 0.7403\n",
      "Epoch 37/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6520 - acc: 0.5000\n",
      "Epoch 00037: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5887 - acc: 0.6645 - val_loss: 0.5678 - val_acc: 0.7403\n",
      "Epoch 38/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5641 - acc: 0.6250\n",
      "Epoch 00038: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5861 - acc: 0.6645 - val_loss: 0.5646 - val_acc: 0.7403\n",
      "Epoch 39/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5447 - acc: 0.7500\n",
      "Epoch 00039: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5835 - acc: 0.6645 - val_loss: 0.5612 - val_acc: 0.7403\n",
      "Epoch 40/350\n",
      "11/19 [================>.............] - ETA: 0s - loss: 0.5856 - acc: 0.6648\n",
      "Epoch 00040: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5809 - acc: 0.6645 - val_loss: 0.5577 - val_acc: 0.7403\n",
      "Epoch 41/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5332 - acc: 0.7500\n",
      "Epoch 00041: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5783 - acc: 0.6645 - val_loss: 0.5543 - val_acc: 0.7403\n",
      "Epoch 42/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5150 - acc: 0.7500\n",
      "Epoch 00042: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5757 - acc: 0.6645 - val_loss: 0.5510 - val_acc: 0.7403\n",
      "Epoch 43/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5234 - acc: 0.7500\n",
      "Epoch 00043: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5732 - acc: 0.6645 - val_loss: 0.5478 - val_acc: 0.7403\n",
      "Epoch 44/350\n",
      "10/19 [==============>...............] - ETA: 0s - loss: 0.5611 - acc: 0.7250\n",
      "Epoch 00044: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5708 - acc: 0.6645 - val_loss: 0.5446 - val_acc: 0.7403\n",
      "Epoch 45/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.5550 - acc: 0.6823\n",
      "Epoch 00045: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5684 - acc: 0.6645 - val_loss: 0.5414 - val_acc: 0.7403\n",
      "Epoch 46/350\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.5658 - acc: 0.6607\n",
      "Epoch 00046: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5661 - acc: 0.6645 - val_loss: 0.5384 - val_acc: 0.7403\n",
      "Epoch 47/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5096 - acc: 0.7500\n",
      "Epoch 00047: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5639 - acc: 0.6645 - val_loss: 0.5354 - val_acc: 0.7403\n",
      "Epoch 48/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5472 - acc: 0.6875\n",
      "Epoch 00048: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5616 - acc: 0.6645 - val_loss: 0.5325 - val_acc: 0.7403\n",
      "Epoch 49/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5595 - acc: 0.6645\n",
      "Epoch 00049: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5595 - acc: 0.6645 - val_loss: 0.5295 - val_acc: 0.7403\n",
      "Epoch 50/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5573 - acc: 0.6645\n",
      "Epoch 00050: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5573 - acc: 0.6645 - val_loss: 0.5267 - val_acc: 0.7403\n",
      "Epoch 51/350\n",
      "11/19 [================>.............] - ETA: 0s - loss: 0.5583 - acc: 0.6705\n",
      "Epoch 00051: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5552 - acc: 0.6645 - val_loss: 0.5239 - val_acc: 0.7403\n",
      "Epoch 52/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5561 - acc: 0.6250\n",
      "Epoch 00052: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5532 - acc: 0.6645 - val_loss: 0.5212 - val_acc: 0.7403\n",
      "Epoch 53/350\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.5572 - acc: 0.6587\n",
      "Epoch 00053: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5512 - acc: 0.6645 - val_loss: 0.5187 - val_acc: 0.7403\n",
      "Epoch 54/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.5432 - acc: 0.6654\n",
      "Epoch 00054: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5494 - acc: 0.6645 - val_loss: 0.5158 - val_acc: 0.7403\n",
      "Epoch 55/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.5514 - acc: 0.6507\n",
      "Epoch 00055: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5474 - acc: 0.6645 - val_loss: 0.5135 - val_acc: 0.7403\n",
      "Epoch 56/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4147 - acc: 0.7500\n",
      "Epoch 00056: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5457 - acc: 0.6645 - val_loss: 0.5108 - val_acc: 0.7403\n",
      "Epoch 57/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5439 - acc: 0.6645\n",
      "Epoch 00057: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5439 - acc: 0.6645 - val_loss: 0.5083 - val_acc: 0.7403\n",
      "Epoch 58/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6730 - acc: 0.6250\n",
      "Epoch 00058: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5422 - acc: 0.6645 - val_loss: 0.5061 - val_acc: 0.7403\n",
      "Epoch 59/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4711 - acc: 0.7500\n",
      "Epoch 00059: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5408 - acc: 0.6645 - val_loss: 0.5036 - val_acc: 0.7403\n",
      "Epoch 60/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6040 - acc: 0.6875\n",
      "Epoch 00060: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5391 - acc: 0.6645 - val_loss: 0.5015 - val_acc: 0.7403\n",
      "Epoch 61/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5426 - acc: 0.7500\n",
      "Epoch 00061: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5377 - acc: 0.6645 - val_loss: 0.4993 - val_acc: 0.7403\n",
      "Epoch 62/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5759 - acc: 0.5625\n",
      "Epoch 00062: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5362 - acc: 0.6645 - val_loss: 0.4974 - val_acc: 0.7403\n",
      "Epoch 63/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5113 - acc: 0.7500\n",
      "Epoch 00063: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5349 - acc: 0.6645 - val_loss: 0.4953 - val_acc: 0.7403\n",
      "Epoch 64/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.7163 - acc: 0.5000\n",
      "Epoch 00064: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5336 - acc: 0.6645 - val_loss: 0.4935 - val_acc: 0.7403\n",
      "Epoch 65/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5819 - acc: 0.4375\n",
      "Epoch 00065: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5324 - acc: 0.6645 - val_loss: 0.4916 - val_acc: 0.7403\n",
      "Epoch 66/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4585 - acc: 0.8125\n",
      "Epoch 00066: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5313 - acc: 0.6645 - val_loss: 0.4897 - val_acc: 0.7403\n",
      "Epoch 67/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6165 - acc: 0.6875\n",
      "Epoch 00067: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301 - acc: 0.6645 - val_loss: 0.4881 - val_acc: 0.7403\n",
      "Epoch 68/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5607 - acc: 0.5625\n",
      "Epoch 00068: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5290 - acc: 0.6645 - val_loss: 0.4865 - val_acc: 0.7403\n",
      "Epoch 69/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4018 - acc: 0.8125\n",
      "Epoch 00069: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5280 - acc: 0.6645 - val_loss: 0.4849 - val_acc: 0.7403\n",
      "Epoch 70/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5035 - acc: 0.6250\n",
      "Epoch 00070: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5270 - acc: 0.6645 - val_loss: 0.4832 - val_acc: 0.7403\n",
      "Epoch 71/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4513 - acc: 0.5625\n",
      "Epoch 00071: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5259 - acc: 0.6645 - val_loss: 0.4818 - val_acc: 0.7403\n",
      "Epoch 72/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5609 - acc: 0.7500\n",
      "Epoch 00072: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5250 - acc: 0.6645 - val_loss: 0.4804 - val_acc: 0.7403\n",
      "Epoch 73/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5551 - acc: 0.6250\n",
      "Epoch 00073: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5240 - acc: 0.6645 - val_loss: 0.4789 - val_acc: 0.7403\n",
      "Epoch 74/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.5213 - acc: 0.6701\n",
      "Epoch 00074: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5231 - acc: 0.6645 - val_loss: 0.4775 - val_acc: 0.7403\n",
      "Epoch 75/350\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.5390 - acc: 0.6298\n",
      "Epoch 00075: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5222 - acc: 0.6645 - val_loss: 0.4762 - val_acc: 0.7403\n",
      "Epoch 76/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3442 - acc: 0.9375\n",
      "Epoch 00076: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5214 - acc: 0.6645 - val_loss: 0.4748 - val_acc: 0.7403\n",
      "Epoch 77/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4060 - acc: 0.6875\n",
      "Epoch 00077: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5206 - acc: 0.6645 - val_loss: 0.4735 - val_acc: 0.7403\n",
      "Epoch 78/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3546 - acc: 0.8125\n",
      "Epoch 00078: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5197 - acc: 0.6645 - val_loss: 0.4723 - val_acc: 0.7403\n",
      "Epoch 79/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4865 - acc: 0.5625\n",
      "Epoch 00079: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5190 - acc: 0.6645 - val_loss: 0.4711 - val_acc: 0.7403\n",
      "Epoch 80/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4518 - acc: 0.6875\n",
      "Epoch 00080: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5183 - acc: 0.6645 - val_loss: 0.4701 - val_acc: 0.7403\n",
      "Epoch 81/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4461 - acc: 0.7500\n",
      "Epoch 00081: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5176 - acc: 0.6645 - val_loss: 0.4687 - val_acc: 0.7403\n",
      "Epoch 82/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.5020 - acc: 0.6917\n",
      "Epoch 00082: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5169 - acc: 0.6645 - val_loss: 0.4676 - val_acc: 0.7403\n",
      "Epoch 83/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5715 - acc: 0.6250\n",
      "Epoch 00083: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5163 - acc: 0.6645 - val_loss: 0.4666 - val_acc: 0.7403\n",
      "Epoch 84/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5508 - acc: 0.6250\n",
      "Epoch 00084: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5157 - acc: 0.6645 - val_loss: 0.4656 - val_acc: 0.7403\n",
      "Epoch 85/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6204 - acc: 0.5000\n",
      "Epoch 00085: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5151 - acc: 0.6645 - val_loss: 0.4645 - val_acc: 0.7403\n",
      "Epoch 86/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5701 - acc: 0.5625\n",
      "Epoch 00086: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5144 - acc: 0.6645 - val_loss: 0.4638 - val_acc: 0.7403\n",
      "Epoch 87/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3316 - acc: 0.8125\n",
      "Epoch 00087: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5140 - acc: 0.6645 - val_loss: 0.4627 - val_acc: 0.7403\n",
      "Epoch 88/350\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.5135 - acc: 0.6523\n",
      "Epoch 00088: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5134 - acc: 0.6645 - val_loss: 0.4619 - val_acc: 0.7403\n",
      "Epoch 89/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4045 - acc: 0.6875\n",
      "Epoch 00089: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5128 - acc: 0.6645 - val_loss: 0.4611 - val_acc: 0.7403\n",
      "Epoch 90/350\n",
      " 7/19 [==========>...................] - ETA: 0s - loss: 0.5290 - acc: 0.6607\n",
      "Epoch 00090: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5123 - acc: 0.6645 - val_loss: 0.4604 - val_acc: 0.7403\n",
      "Epoch 91/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5527 - acc: 0.6250\n",
      "Epoch 00091: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5118 - acc: 0.6645 - val_loss: 0.4596 - val_acc: 0.7403\n",
      "Epoch 92/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5114 - acc: 0.6645\n",
      "Epoch 00092: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5114 - acc: 0.6645 - val_loss: 0.4586 - val_acc: 0.7403\n",
      "Epoch 93/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4910 - acc: 0.6875\n",
      "Epoch 00093: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5108 - acc: 0.6645 - val_loss: 0.4579 - val_acc: 0.7403\n",
      "Epoch 94/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6980 - acc: 0.4375\n",
      "Epoch 00094: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5103 - acc: 0.6645 - val_loss: 0.4571 - val_acc: 0.7403\n",
      "Epoch 95/350\n",
      "11/19 [================>.............] - ETA: 0s - loss: 0.5295 - acc: 0.6477\n",
      "Epoch 00095: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5098 - acc: 0.6645 - val_loss: 0.4563 - val_acc: 0.7403\n",
      "Epoch 96/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3152 - acc: 0.8750\n",
      "Epoch 00096: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5094 - acc: 0.6645 - val_loss: 0.4555 - val_acc: 0.7403\n",
      "Epoch 97/350\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.5036 - acc: 0.6696\n",
      "Epoch 00097: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5089 - acc: 0.6645 - val_loss: 0.4547 - val_acc: 0.7403\n",
      "Epoch 98/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6043 - acc: 0.5625\n",
      "Epoch 00098: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5084 - acc: 0.6645 - val_loss: 0.4541 - val_acc: 0.7403\n",
      "Epoch 99/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4419 - acc: 0.6875\n",
      "Epoch 00099: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5080 - acc: 0.6645 - val_loss: 0.4534 - val_acc: 0.7403\n",
      "Epoch 100/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3802 - acc: 0.8125\n",
      "Epoch 00100: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5076 - acc: 0.6645 - val_loss: 0.4525 - val_acc: 0.7403\n",
      "Epoch 101/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.5139 - acc: 0.6507\n",
      "Epoch 00101: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5072 - acc: 0.6645 - val_loss: 0.4519 - val_acc: 0.7403\n",
      "Epoch 102/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4834 - acc: 0.6875\n",
      "Epoch 00102: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5068 - acc: 0.6645 - val_loss: 0.4513 - val_acc: 0.7403\n",
      "Epoch 103/350\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4923 - acc: 0.6914\n",
      "Epoch 00103: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5064 - acc: 0.6645 - val_loss: 0.4506 - val_acc: 0.7403\n",
      "Epoch 104/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5123 - acc: 0.6875\n",
      "Epoch 00104: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5060 - acc: 0.6645 - val_loss: 0.4499 - val_acc: 0.7403\n",
      "Epoch 105/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3682 - acc: 0.8125\n",
      "Epoch 00105: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5056 - acc: 0.6645 - val_loss: 0.4495 - val_acc: 0.7403\n",
      "Epoch 106/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5052 - acc: 0.6645\n",
      "Epoch 00106: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5052 - acc: 0.6645 - val_loss: 0.4491 - val_acc: 0.7403\n",
      "Epoch 107/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.7595 - acc: 0.5625\n",
      "Epoch 00107: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5048 - acc: 0.6645 - val_loss: 0.4485 - val_acc: 0.7403\n",
      "Epoch 108/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4900 - acc: 0.6728\n",
      "Epoch 00108: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5044 - acc: 0.6645 - val_loss: 0.4478 - val_acc: 0.7403\n",
      "Epoch 109/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5039 - acc: 0.6645\n",
      "Epoch 00109: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5039 - acc: 0.6645 - val_loss: 0.4473 - val_acc: 0.7403\n",
      "Epoch 110/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3511 - acc: 0.8125\n",
      "Epoch 00110: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5036 - acc: 0.6645 - val_loss: 0.4467 - val_acc: 0.7403\n",
      "Epoch 111/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5378 - acc: 0.5000\n",
      "Epoch 00111: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5032 - acc: 0.6645 - val_loss: 0.4462 - val_acc: 0.7403\n",
      "Epoch 112/350\n",
      " 8/19 [===========>..................] - ETA: 0s - loss: 0.5094 - acc: 0.6953\n",
      "Epoch 00112: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5029 - acc: 0.6645 - val_loss: 0.4454 - val_acc: 0.7403\n",
      "Epoch 113/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.5197 - acc: 0.6458\n",
      "Epoch 00113: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5025 - acc: 0.6645 - val_loss: 0.4450 - val_acc: 0.7403\n",
      "Epoch 114/350\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4819 - acc: 0.6758\n",
      "Epoch 00114: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5021 - acc: 0.6645 - val_loss: 0.4444 - val_acc: 0.7403\n",
      "Epoch 115/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4927 - acc: 0.5625\n",
      "Epoch 00115: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5018 - acc: 0.6645 - val_loss: 0.4438 - val_acc: 0.7403\n",
      "Epoch 116/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.4939 - acc: 0.6823\n",
      "Epoch 00116: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5014 - acc: 0.6645 - val_loss: 0.4434 - val_acc: 0.7403\n",
      "Epoch 117/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4621 - acc: 0.6250\n",
      "Epoch 00117: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5011 - acc: 0.6645 - val_loss: 0.4428 - val_acc: 0.7403\n",
      "Epoch 118/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6125 - acc: 0.5625\n",
      "Epoch 00118: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5008 - acc: 0.6645 - val_loss: 0.4424 - val_acc: 0.7403\n",
      "Epoch 119/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4519 - acc: 0.5625\n",
      "Epoch 00119: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5004 - acc: 0.6645 - val_loss: 0.4420 - val_acc: 0.7403\n",
      "Epoch 120/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4999 - acc: 0.6667\n",
      "Epoch 00120: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5000 - acc: 0.6645 - val_loss: 0.4417 - val_acc: 0.7403\n",
      "Epoch 121/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5525 - acc: 0.5625\n",
      "Epoch 00121: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4997 - acc: 0.6645 - val_loss: 0.4412 - val_acc: 0.7403\n",
      "Epoch 122/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5190 - acc: 0.6250\n",
      "Epoch 00122: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4994 - acc: 0.6645 - val_loss: 0.4408 - val_acc: 0.7403\n",
      "Epoch 123/350\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.4900 - acc: 0.6562\n",
      "Epoch 00123: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4991 - acc: 0.6645 - val_loss: 0.4403 - val_acc: 0.7403\n",
      "Epoch 124/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6420 - acc: 0.6250\n",
      "Epoch 00124: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4987 - acc: 0.6645 - val_loss: 0.4401 - val_acc: 0.7403\n",
      "Epoch 125/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5493 - acc: 0.6250\n",
      "Epoch 00125: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4984 - acc: 0.6645 - val_loss: 0.4397 - val_acc: 0.7403\n",
      "Epoch 126/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4981 - acc: 0.6645\n",
      "Epoch 00126: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4981 - acc: 0.6645 - val_loss: 0.4392 - val_acc: 0.7403\n",
      "Epoch 127/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4141 - acc: 0.7500\n",
      "Epoch 00127: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4977 - acc: 0.6645 - val_loss: 0.4389 - val_acc: 0.7403\n",
      "Epoch 128/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.7587 - acc: 0.5000\n",
      "Epoch 00128: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4974 - acc: 0.6645 - val_loss: 0.4384 - val_acc: 0.7403\n",
      "Epoch 129/350\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.4900 - acc: 0.6490\n",
      "Epoch 00129: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4971 - acc: 0.6645 - val_loss: 0.4380 - val_acc: 0.7403\n",
      "Epoch 130/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5213 - acc: 0.5625\n",
      "Epoch 00130: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4967 - acc: 0.6645 - val_loss: 0.4376 - val_acc: 0.7403\n",
      "Epoch 131/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4157 - acc: 0.7500\n",
      "Epoch 00131: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4964 - acc: 0.6645 - val_loss: 0.4373 - val_acc: 0.7403\n",
      "Epoch 132/350\n",
      " 8/19 [===========>..................] - ETA: 0s - loss: 0.4273 - acc: 0.7188\n",
      "Epoch 00132: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4962 - acc: 0.6645 - val_loss: 0.4368 - val_acc: 0.7403\n",
      "Epoch 133/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4919 - acc: 0.6618\n",
      "Epoch 00133: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4958 - acc: 0.6645 - val_loss: 0.4365 - val_acc: 0.7403\n",
      "Epoch 134/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6176 - acc: 0.6250\n",
      "Epoch 00134: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4957 - acc: 0.6645 - val_loss: 0.4364 - val_acc: 0.7403\n",
      "Epoch 135/350\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.4860 - acc: 0.6920\n",
      "Epoch 00135: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4953 - acc: 0.6645 - val_loss: 0.4359 - val_acc: 0.7403\n",
      "Epoch 136/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4992 - acc: 0.6728\n",
      "Epoch 00136: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.4950 - acc: 0.6645 - val_loss: 0.4355 - val_acc: 0.7403\n",
      "Epoch 137/350\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4827 - acc: 0.6914\n",
      "Epoch 00137: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4948 - acc: 0.6645 - val_loss: 0.4350 - val_acc: 0.7403\n",
      "Epoch 138/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5683 - acc: 0.6875\n",
      "Epoch 00138: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4945 - acc: 0.6645 - val_loss: 0.4348 - val_acc: 0.7403\n",
      "Epoch 139/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5796 - acc: 0.6875\n",
      "Epoch 00139: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4943 - acc: 0.6645 - val_loss: 0.4345 - val_acc: 0.7403\n",
      "Epoch 140/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4451 - acc: 0.6875\n",
      "Epoch 00140: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4940 - acc: 0.6645 - val_loss: 0.4341 - val_acc: 0.7403\n",
      "Epoch 141/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5974 - acc: 0.4375\n",
      "Epoch 00141: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4937 - acc: 0.6645 - val_loss: 0.4338 - val_acc: 0.7403\n",
      "Epoch 142/350\n",
      "10/19 [==============>...............] - ETA: 0s - loss: 0.4829 - acc: 0.6625\n",
      "Epoch 00142: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4934 - acc: 0.6645 - val_loss: 0.4334 - val_acc: 0.7403\n",
      "Epoch 143/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5950 - acc: 0.4375\n",
      "Epoch 00143: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4932 - acc: 0.6645 - val_loss: 0.4331 - val_acc: 0.7403\n",
      "Epoch 144/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.5009 - acc: 0.6583\n",
      "Epoch 00144: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4929 - acc: 0.6645 - val_loss: 0.4327 - val_acc: 0.7403\n",
      "Epoch 145/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3162 - acc: 0.8750\n",
      "Epoch 00145: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4927 - acc: 0.6645 - val_loss: 0.4325 - val_acc: 0.7403\n",
      "Epoch 146/350\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4961 - acc: 0.6680\n",
      "Epoch 00146: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4924 - acc: 0.6645 - val_loss: 0.4321 - val_acc: 0.7403\n",
      "Epoch 147/350\n",
      "10/19 [==============>...............] - ETA: 0s - loss: 0.5037 - acc: 0.6687\n",
      "Epoch 00147: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4922 - acc: 0.6645 - val_loss: 0.4317 - val_acc: 0.7403\n",
      "Epoch 148/350\n",
      " 9/19 [=============>................] - ETA: 0s - loss: 0.4615 - acc: 0.6806\n",
      "Epoch 00148: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4919 - acc: 0.6645 - val_loss: 0.4313 - val_acc: 0.7403\n",
      "Epoch 149/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.5108 - acc: 0.6458\n",
      "Epoch 00149: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4917 - acc: 0.6645 - val_loss: 0.4312 - val_acc: 0.7403\n",
      "Epoch 150/350\n",
      "11/19 [================>.............] - ETA: 0s - loss: 0.4642 - acc: 0.7045\n",
      "Epoch 00150: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4914 - acc: 0.6645 - val_loss: 0.4307 - val_acc: 0.7403\n",
      "Epoch 151/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4865 - acc: 0.6736\n",
      "Epoch 00151: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4912 - acc: 0.6678 - val_loss: 0.4304 - val_acc: 0.7403\n",
      "Epoch 152/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4030 - acc: 0.6250\n",
      "Epoch 00152: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4909 - acc: 0.6678 - val_loss: 0.4300 - val_acc: 0.7403\n",
      "Epoch 153/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4618 - acc: 0.6250\n",
      "Epoch 00153: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4906 - acc: 0.6678 - val_loss: 0.4298 - val_acc: 0.7403\n",
      "Epoch 154/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4904 - acc: 0.6678\n",
      "Epoch 00154: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4904 - acc: 0.6678 - val_loss: 0.4294 - val_acc: 0.7403\n",
      "Epoch 155/350\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.5066 - acc: 0.6442\n",
      "Epoch 00155: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4902 - acc: 0.6678 - val_loss: 0.4292 - val_acc: 0.7403\n",
      "Epoch 156/350\n",
      "11/19 [================>.............] - ETA: 0s - loss: 0.4838 - acc: 0.6591\n",
      "Epoch 00156: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4899 - acc: 0.6678 - val_loss: 0.4288 - val_acc: 0.7403\n",
      "Epoch 157/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.4597 - acc: 0.7083\n",
      "Epoch 00157: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4897 - acc: 0.6678 - val_loss: 0.4283 - val_acc: 0.7403\n",
      "Epoch 158/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3734 - acc: 0.8750\n",
      "Epoch 00158: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4895 - acc: 0.6678 - val_loss: 0.4281 - val_acc: 0.7403\n",
      "Epoch 159/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3296 - acc: 0.7500\n",
      "Epoch 00159: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4892 - acc: 0.6678 - val_loss: 0.4278 - val_acc: 0.7403\n",
      "Epoch 160/350\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.5001 - acc: 0.6797\n",
      "Epoch 00160: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4890 - acc: 0.6678 - val_loss: 0.4276 - val_acc: 0.7403\n",
      "Epoch 161/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.4846 - acc: 0.6708\n",
      "Epoch 00161: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4888 - acc: 0.6678 - val_loss: 0.4273 - val_acc: 0.7403\n",
      "Epoch 162/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6249 - acc: 0.6250\n",
      "Epoch 00162: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4886 - acc: 0.6678 - val_loss: 0.4270 - val_acc: 0.7403\n",
      "Epoch 163/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5117 - acc: 0.5000\n",
      "Epoch 00163: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4884 - acc: 0.6678 - val_loss: 0.4268 - val_acc: 0.7403\n",
      "Epoch 164/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5180 - acc: 0.6875\n",
      "Epoch 00164: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4881 - acc: 0.6678 - val_loss: 0.4265 - val_acc: 0.7403\n",
      "Epoch 165/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4197 - acc: 0.8125\n",
      "Epoch 00165: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4879 - acc: 0.6678 - val_loss: 0.4263 - val_acc: 0.7403\n",
      "Epoch 166/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4500 - acc: 0.8125\n",
      "Epoch 00166: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4877 - acc: 0.6711 - val_loss: 0.4259 - val_acc: 0.7403\n",
      "Epoch 167/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5437 - acc: 0.6875\n",
      "Epoch 00167: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4876 - acc: 0.6711 - val_loss: 0.4257 - val_acc: 0.7403\n",
      "Epoch 168/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5358 - acc: 0.6875\n",
      "Epoch 00168: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4873 - acc: 0.6711 - val_loss: 0.4255 - val_acc: 0.7403\n",
      "Epoch 169/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3559 - acc: 0.8125\n",
      "Epoch 00169: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4871 - acc: 0.6711 - val_loss: 0.4253 - val_acc: 0.7403\n",
      "Epoch 170/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5648 - acc: 0.5000\n",
      "Epoch 00170: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4869 - acc: 0.6711 - val_loss: 0.4251 - val_acc: 0.7403\n",
      "Epoch 171/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6734 - acc: 0.5000\n",
      "Epoch 00171: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4867 - acc: 0.6711 - val_loss: 0.4248 - val_acc: 0.7403\n",
      "Epoch 172/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3848 - acc: 0.7500\n",
      "Epoch 00172: val_acc did not improve from 0.74026\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4865 - acc: 0.6711 - val_loss: 0.4247 - val_acc: 0.7403\n",
      "Epoch 173/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3995 - acc: 0.6875\n",
      "Epoch 00173: val_acc improved from 0.74026 to 0.77922, saving model to diabetes.h5\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4863 - acc: 0.6941 - val_loss: 0.4244 - val_acc: 0.7792\n",
      "Epoch 174/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4650 - acc: 0.8125\n",
      "Epoch 00174: val_acc did not improve from 0.77922\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4862 - acc: 0.7533 - val_loss: 0.4239 - val_acc: 0.7792\n",
      "Epoch 175/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.2074 - acc: 1.0000\n",
      "Epoch 00175: val_acc did not improve from 0.77922\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4859 - acc: 0.7533 - val_loss: 0.4237 - val_acc: 0.7792\n",
      "Epoch 176/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3806 - acc: 0.8750\n",
      "Epoch 00176: val_acc did not improve from 0.77922\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4858 - acc: 0.7533 - val_loss: 0.4236 - val_acc: 0.7792\n",
      "Epoch 177/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6040 - acc: 0.5625\n",
      "Epoch 00177: val_acc improved from 0.77922 to 0.79221, saving model to diabetes.h5\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4856 - acc: 0.7533 - val_loss: 0.4234 - val_acc: 0.7922\n",
      "Epoch 178/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4737 - acc: 0.8750\n",
      "Epoch 00178: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4854 - acc: 0.7533 - val_loss: 0.4232 - val_acc: 0.7922\n",
      "Epoch 179/350\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.4730 - acc: 0.7644\n",
      "Epoch 00179: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4852 - acc: 0.7533 - val_loss: 0.4230 - val_acc: 0.7922\n",
      "Epoch 180/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3895 - acc: 0.8750\n",
      "Epoch 00180: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4851 - acc: 0.7566 - val_loss: 0.4226 - val_acc: 0.7922\n",
      "Epoch 181/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5385 - acc: 0.7500\n",
      "Epoch 00181: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4848 - acc: 0.7599 - val_loss: 0.4226 - val_acc: 0.7922\n",
      "Epoch 182/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.2443 - acc: 0.9375\n",
      "Epoch 00182: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4846 - acc: 0.7599 - val_loss: 0.4224 - val_acc: 0.7922\n",
      "Epoch 183/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6082 - acc: 0.6250\n",
      "Epoch 00183: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4845 - acc: 0.7632 - val_loss: 0.4221 - val_acc: 0.7922\n",
      "Epoch 184/350\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4644 - acc: 0.7773\n",
      "Epoch 00184: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4843 - acc: 0.7632 - val_loss: 0.4219 - val_acc: 0.7922\n",
      "Epoch 185/350\n",
      "10/19 [==============>...............] - ETA: 0s - loss: 0.5090 - acc: 0.7437\n",
      "Epoch 00185: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4841 - acc: 0.7632 - val_loss: 0.4218 - val_acc: 0.7922\n",
      "Epoch 186/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5492 - acc: 0.8125\n",
      "Epoch 00186: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4839 - acc: 0.7632 - val_loss: 0.4215 - val_acc: 0.7922\n",
      "Epoch 187/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.4906 - acc: 0.7542\n",
      "Epoch 00187: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4837 - acc: 0.7632 - val_loss: 0.4214 - val_acc: 0.7922\n",
      "Epoch 188/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5992 - acc: 0.8125\n",
      "Epoch 00188: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4836 - acc: 0.7632 - val_loss: 0.4212 - val_acc: 0.7922\n",
      "Epoch 189/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5309 - acc: 0.8125\n",
      "Epoch 00189: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4834 - acc: 0.7632 - val_loss: 0.4211 - val_acc: 0.7922\n",
      "Epoch 190/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4016 - acc: 0.7500\n",
      "Epoch 00190: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4832 - acc: 0.7632 - val_loss: 0.4208 - val_acc: 0.7922\n",
      "Epoch 191/350\n",
      " 9/19 [=============>................] - ETA: 0s - loss: 0.4840 - acc: 0.7778\n",
      "Epoch 00191: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4830 - acc: 0.7632 - val_loss: 0.4205 - val_acc: 0.7922\n",
      "Epoch 192/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4379 - acc: 0.9375\n",
      "Epoch 00192: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4828 - acc: 0.7632 - val_loss: 0.4204 - val_acc: 0.7922\n",
      "Epoch 193/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4577 - acc: 0.7500\n",
      "Epoch 00193: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4827 - acc: 0.7632 - val_loss: 0.4201 - val_acc: 0.7922\n",
      "Epoch 194/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.4781 - acc: 0.7708\n",
      "Epoch 00194: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4825 - acc: 0.7632 - val_loss: 0.4201 - val_acc: 0.7922\n",
      "Epoch 195/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.4927 - acc: 0.7396\n",
      "Epoch 00195: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4823 - acc: 0.7632 - val_loss: 0.4199 - val_acc: 0.7922\n",
      "Epoch 196/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4778 - acc: 0.8750\n",
      "Epoch 00196: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4822 - acc: 0.7632 - val_loss: 0.4197 - val_acc: 0.7922\n",
      "Epoch 197/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3575 - acc: 0.8750\n",
      "Epoch 00197: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4820 - acc: 0.7632 - val_loss: 0.4195 - val_acc: 0.7922\n",
      "Epoch 198/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3371 - acc: 1.0000\n",
      "Epoch 00198: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4818 - acc: 0.7632 - val_loss: 0.4194 - val_acc: 0.7922\n",
      "Epoch 199/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3725 - acc: 0.8750\n",
      "Epoch 00199: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4816 - acc: 0.7697 - val_loss: 0.4193 - val_acc: 0.7922\n",
      "Epoch 200/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.5038 - acc: 0.7500\n",
      "Epoch 00200: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4815 - acc: 0.7730 - val_loss: 0.4192 - val_acc: 0.7922\n",
      "Epoch 201/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5552 - acc: 0.6875\n",
      "Epoch 00201: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4813 - acc: 0.7730 - val_loss: 0.4190 - val_acc: 0.7922\n",
      "Epoch 202/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6159 - acc: 0.5625\n",
      "Epoch 00202: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4812 - acc: 0.7763 - val_loss: 0.4185 - val_acc: 0.7922\n",
      "Epoch 203/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5062 - acc: 0.7500\n",
      "Epoch 00203: val_acc did not improve from 0.79221\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4810 - acc: 0.7763 - val_loss: 0.4186 - val_acc: 0.7922\n",
      "Epoch 204/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3882 - acc: 0.8125\n",
      "Epoch 00204: val_acc improved from 0.79221 to 0.80519, saving model to diabetes.h5\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4808 - acc: 0.7763 - val_loss: 0.4183 - val_acc: 0.8052\n",
      "Epoch 205/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4613 - acc: 0.8125\n",
      "Epoch 00205: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4806 - acc: 0.7763 - val_loss: 0.4181 - val_acc: 0.8052\n",
      "Epoch 206/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4150 - acc: 0.7500\n",
      "Epoch 00206: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4805 - acc: 0.7796 - val_loss: 0.4178 - val_acc: 0.8052\n",
      "Epoch 207/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4657 - acc: 0.8125\n",
      "Epoch 00207: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4803 - acc: 0.7763 - val_loss: 0.4178 - val_acc: 0.8052\n",
      "Epoch 208/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4481 - acc: 0.7500\n",
      "Epoch 00208: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4802 - acc: 0.7763 - val_loss: 0.4175 - val_acc: 0.8052\n",
      "Epoch 209/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.7189 - acc: 0.5000\n",
      "Epoch 00209: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4800 - acc: 0.7730 - val_loss: 0.4174 - val_acc: 0.8052\n",
      "Epoch 210/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3952 - acc: 0.8750\n",
      "Epoch 00210: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4798 - acc: 0.7730 - val_loss: 0.4172 - val_acc: 0.8052\n",
      "Epoch 211/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4797 - acc: 0.7730\n",
      "Epoch 00211: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4797 - acc: 0.7730 - val_loss: 0.4170 - val_acc: 0.8052\n",
      "Epoch 212/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4346 - acc: 0.8125\n",
      "Epoch 00212: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4795 - acc: 0.7730 - val_loss: 0.4168 - val_acc: 0.8052\n",
      "Epoch 213/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4794 - acc: 0.7730\n",
      "Epoch 00213: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4794 - acc: 0.7730 - val_loss: 0.4167 - val_acc: 0.8052\n",
      "Epoch 214/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4799 - acc: 0.7721\n",
      "Epoch 00214: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4792 - acc: 0.7763 - val_loss: 0.4165 - val_acc: 0.8052\n",
      "Epoch 215/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3071 - acc: 0.8750\n",
      "Epoch 00215: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4791 - acc: 0.7763 - val_loss: 0.4163 - val_acc: 0.8052\n",
      "Epoch 216/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.4789 - acc: 0.7833\n",
      "Epoch 00216: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4790 - acc: 0.7763 - val_loss: 0.4161 - val_acc: 0.8052\n",
      "Epoch 217/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4015 - acc: 0.8750\n",
      "Epoch 00217: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4788 - acc: 0.7763 - val_loss: 0.4159 - val_acc: 0.8052\n",
      "Epoch 218/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5148 - acc: 0.7500\n",
      "Epoch 00218: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4786 - acc: 0.7763 - val_loss: 0.4158 - val_acc: 0.8052\n",
      "Epoch 219/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4997 - acc: 0.7500\n",
      "Epoch 00219: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4785 - acc: 0.7763 - val_loss: 0.4156 - val_acc: 0.8052\n",
      "Epoch 220/350\n",
      " 8/19 [===========>..................] - ETA: 0s - loss: 0.4364 - acc: 0.8125\n",
      "Epoch 00220: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4783 - acc: 0.7730 - val_loss: 0.4155 - val_acc: 0.8052\n",
      "Epoch 221/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5840 - acc: 0.5625\n",
      "Epoch 00221: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4782 - acc: 0.7697 - val_loss: 0.4154 - val_acc: 0.8052\n",
      "Epoch 222/350\n",
      "11/19 [================>.............] - ETA: 0s - loss: 0.4787 - acc: 0.7955\n",
      "Epoch 00222: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4780 - acc: 0.7697 - val_loss: 0.4151 - val_acc: 0.8052\n",
      "Epoch 223/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4452 - acc: 0.8125\n",
      "Epoch 00223: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4779 - acc: 0.7730 - val_loss: 0.4151 - val_acc: 0.8052\n",
      "Epoch 224/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4777 - acc: 0.7730\n",
      "Epoch 00224: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4777 - acc: 0.7730 - val_loss: 0.4148 - val_acc: 0.8052\n",
      "Epoch 225/350\n",
      "11/19 [================>.............] - ETA: 0s - loss: 0.4817 - acc: 0.7727\n",
      "Epoch 00225: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4776 - acc: 0.7697 - val_loss: 0.4147 - val_acc: 0.8052\n",
      "Epoch 226/350\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.4335 - acc: 0.7812\n",
      "Epoch 00226: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4775 - acc: 0.7730 - val_loss: 0.4145 - val_acc: 0.8052\n",
      "Epoch 227/350\n",
      " 8/19 [===========>..................] - ETA: 0s - loss: 0.5234 - acc: 0.7500\n",
      "Epoch 00227: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4773 - acc: 0.7730 - val_loss: 0.4145 - val_acc: 0.8052\n",
      "Epoch 228/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6580 - acc: 0.8750\n",
      "Epoch 00228: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4772 - acc: 0.7697 - val_loss: 0.4143 - val_acc: 0.8052\n",
      "Epoch 229/350\n",
      " 9/19 [=============>................] - ETA: 0s - loss: 0.4505 - acc: 0.8125\n",
      "Epoch 00229: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4770 - acc: 0.7697 - val_loss: 0.4141 - val_acc: 0.8052\n",
      "Epoch 230/350\n",
      " 7/19 [==========>...................] - ETA: 0s - loss: 0.5142 - acc: 0.7500\n",
      "Epoch 00230: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4769 - acc: 0.7697 - val_loss: 0.4140 - val_acc: 0.8052\n",
      "Epoch 231/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6049 - acc: 0.6875\n",
      "Epoch 00231: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4767 - acc: 0.7697 - val_loss: 0.4140 - val_acc: 0.8052\n",
      "Epoch 232/350\n",
      "10/19 [==============>...............] - ETA: 0s - loss: 0.4635 - acc: 0.7812\n",
      "Epoch 00232: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4765 - acc: 0.7697 - val_loss: 0.4137 - val_acc: 0.8052\n",
      "Epoch 233/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4862 - acc: 0.6875\n",
      "Epoch 00233: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4764 - acc: 0.7697 - val_loss: 0.4135 - val_acc: 0.8052\n",
      "Epoch 234/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4374 - acc: 0.8750\n",
      "Epoch 00234: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4763 - acc: 0.7730 - val_loss: 0.4133 - val_acc: 0.8052\n",
      "Epoch 235/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.4723 - acc: 0.7833\n",
      "Epoch 00235: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4761 - acc: 0.7730 - val_loss: 0.4132 - val_acc: 0.8052\n",
      "Epoch 236/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5133 - acc: 0.7500\n",
      "Epoch 00236: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4760 - acc: 0.7697 - val_loss: 0.4131 - val_acc: 0.8052\n",
      "Epoch 237/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3217 - acc: 0.8125\n",
      "Epoch 00237: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4758 - acc: 0.7697 - val_loss: 0.4130 - val_acc: 0.8052\n",
      "Epoch 238/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3495 - acc: 0.8750\n",
      "Epoch 00238: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4757 - acc: 0.7697 - val_loss: 0.4128 - val_acc: 0.8052\n",
      "Epoch 239/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4504 - acc: 0.8750\n",
      "Epoch 00239: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4755 - acc: 0.7730 - val_loss: 0.4127 - val_acc: 0.8052\n",
      "Epoch 240/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4096 - acc: 0.7500\n",
      "Epoch 00240: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4754 - acc: 0.7730 - val_loss: 0.4127 - val_acc: 0.8052\n",
      "Epoch 241/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3892 - acc: 0.7500\n",
      "Epoch 00241: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4752 - acc: 0.7730 - val_loss: 0.4124 - val_acc: 0.8052\n",
      "Epoch 242/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4668 - acc: 0.7500\n",
      "Epoch 00242: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4752 - acc: 0.7730 - val_loss: 0.4126 - val_acc: 0.8052\n",
      "Epoch 243/350\n",
      "10/19 [==============>...............] - ETA: 0s - loss: 0.4829 - acc: 0.7500\n",
      "Epoch 00243: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4749 - acc: 0.7730 - val_loss: 0.4123 - val_acc: 0.8052\n",
      "Epoch 244/350\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4720 - acc: 0.7656\n",
      "Epoch 00244: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4748 - acc: 0.7730 - val_loss: 0.4121 - val_acc: 0.8052\n",
      "Epoch 245/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3008 - acc: 0.9375\n",
      "Epoch 00245: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4746 - acc: 0.7730 - val_loss: 0.4121 - val_acc: 0.8052\n",
      "Epoch 246/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.5048 - acc: 0.7500\n",
      "Epoch 00246: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4745 - acc: 0.7763 - val_loss: 0.4120 - val_acc: 0.8052\n",
      "Epoch 247/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.4776 - acc: 0.8021\n",
      "Epoch 00247: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4744 - acc: 0.7763 - val_loss: 0.4119 - val_acc: 0.8052\n",
      "Epoch 248/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4797 - acc: 0.7574\n",
      "Epoch 00248: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4742 - acc: 0.7763 - val_loss: 0.4118 - val_acc: 0.8052\n",
      "Epoch 249/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4781 - acc: 0.7812\n",
      "Epoch 00249: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4741 - acc: 0.7763 - val_loss: 0.4115 - val_acc: 0.8052\n",
      "Epoch 250/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4788 - acc: 0.8750\n",
      "Epoch 00250: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4739 - acc: 0.7763 - val_loss: 0.4114 - val_acc: 0.8052\n",
      "Epoch 251/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4738 - acc: 0.7763\n",
      "Epoch 00251: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4738 - acc: 0.7763 - val_loss: 0.4111 - val_acc: 0.8052\n",
      "Epoch 252/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4790 - acc: 0.7674\n",
      "Epoch 00252: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4736 - acc: 0.7763 - val_loss: 0.4111 - val_acc: 0.8052\n",
      "Epoch 253/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4923 - acc: 0.7500\n",
      "Epoch 00253: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4735 - acc: 0.7763 - val_loss: 0.4112 - val_acc: 0.8052\n",
      "Epoch 254/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5230 - acc: 0.7500\n",
      "Epoch 00254: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4733 - acc: 0.7763 - val_loss: 0.4111 - val_acc: 0.8052\n",
      "Epoch 255/350\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.4866 - acc: 0.7644\n",
      "Epoch 00255: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4732 - acc: 0.7763 - val_loss: 0.4109 - val_acc: 0.8052\n",
      "Epoch 256/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6003 - acc: 0.6875\n",
      "Epoch 00256: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4731 - acc: 0.7763 - val_loss: 0.4108 - val_acc: 0.8052\n",
      "Epoch 257/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4561 - acc: 0.6875\n",
      "Epoch 00257: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4730 - acc: 0.7763 - val_loss: 0.4106 - val_acc: 0.8052\n",
      "Epoch 258/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4615 - acc: 0.8125\n",
      "Epoch 00258: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4728 - acc: 0.7763 - val_loss: 0.4105 - val_acc: 0.8052\n",
      "Epoch 259/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6296 - acc: 0.9375\n",
      "Epoch 00259: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4727 - acc: 0.7796 - val_loss: 0.4103 - val_acc: 0.8052\n",
      "Epoch 260/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3029 - acc: 0.8750\n",
      "Epoch 00260: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4725 - acc: 0.7796 - val_loss: 0.4103 - val_acc: 0.8052\n",
      "Epoch 261/350\n",
      " 8/19 [===========>..................] - ETA: 0s - loss: 0.4323 - acc: 0.8203\n",
      "Epoch 00261: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4724 - acc: 0.7796 - val_loss: 0.4100 - val_acc: 0.8052\n",
      "Epoch 262/350\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.4991 - acc: 0.7679\n",
      "Epoch 00262: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4722 - acc: 0.7796 - val_loss: 0.4101 - val_acc: 0.8052\n",
      "Epoch 263/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4656 - acc: 0.8750\n",
      "Epoch 00263: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4721 - acc: 0.7796 - val_loss: 0.4099 - val_acc: 0.8052\n",
      "Epoch 264/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3717 - acc: 0.8125\n",
      "Epoch 00264: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4719 - acc: 0.7796 - val_loss: 0.4099 - val_acc: 0.8052\n",
      "Epoch 265/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3331 - acc: 0.8125\n",
      "Epoch 00265: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4719 - acc: 0.7763 - val_loss: 0.4096 - val_acc: 0.8052\n",
      "Epoch 266/350\n",
      " 8/19 [===========>..................] - ETA: 0s - loss: 0.4872 - acc: 0.7500\n",
      "Epoch 00266: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4717 - acc: 0.7796 - val_loss: 0.4097 - val_acc: 0.8052\n",
      "Epoch 267/350\n",
      " 7/19 [==========>...................] - ETA: 0s - loss: 0.4171 - acc: 0.8214\n",
      "Epoch 00267: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4716 - acc: 0.7796 - val_loss: 0.4094 - val_acc: 0.8052\n",
      "Epoch 268/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5143 - acc: 0.6875\n",
      "Epoch 00268: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4714 - acc: 0.7763 - val_loss: 0.4094 - val_acc: 0.8052\n",
      "Epoch 269/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.7143 - acc: 0.8750\n",
      "Epoch 00269: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4713 - acc: 0.7796 - val_loss: 0.4094 - val_acc: 0.8052\n",
      "Epoch 270/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4638 - acc: 0.8125\n",
      "Epoch 00270: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4712 - acc: 0.7829 - val_loss: 0.4092 - val_acc: 0.8052\n",
      "Epoch 271/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3484 - acc: 0.9375\n",
      "Epoch 00271: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4710 - acc: 0.7829 - val_loss: 0.4091 - val_acc: 0.8052\n",
      "Epoch 272/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6263 - acc: 0.8125\n",
      "Epoch 00272: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4709 - acc: 0.7829 - val_loss: 0.4090 - val_acc: 0.8052\n",
      "Epoch 273/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4575 - acc: 0.8750\n",
      "Epoch 00273: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4708 - acc: 0.7829 - val_loss: 0.4088 - val_acc: 0.8052\n",
      "Epoch 274/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5120 - acc: 0.7500\n",
      "Epoch 00274: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4706 - acc: 0.7829 - val_loss: 0.4088 - val_acc: 0.8052\n",
      "Epoch 275/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3561 - acc: 0.9375\n",
      "Epoch 00275: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4705 - acc: 0.7829 - val_loss: 0.4087 - val_acc: 0.8052\n",
      "Epoch 276/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4100 - acc: 0.8125\n",
      "Epoch 00276: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4703 - acc: 0.7829 - val_loss: 0.4085 - val_acc: 0.8052\n",
      "Epoch 277/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6361 - acc: 0.7500\n",
      "Epoch 00277: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4703 - acc: 0.7829 - val_loss: 0.4085 - val_acc: 0.8052\n",
      "Epoch 278/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4409 - acc: 0.8125\n",
      "Epoch 00278: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4701 - acc: 0.7829 - val_loss: 0.4084 - val_acc: 0.8052\n",
      "Epoch 279/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4685 - acc: 0.7500\n",
      "Epoch 00279: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4700 - acc: 0.7862 - val_loss: 0.4081 - val_acc: 0.8052\n",
      "Epoch 280/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4698 - acc: 0.7862\n",
      "Epoch 00280: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4698 - acc: 0.7862 - val_loss: 0.4082 - val_acc: 0.8052\n",
      "Epoch 281/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6171 - acc: 0.6875\n",
      "Epoch 00281: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4697 - acc: 0.7862 - val_loss: 0.4081 - val_acc: 0.8052\n",
      "Epoch 282/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5080 - acc: 0.7500\n",
      "Epoch 00282: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4696 - acc: 0.7862 - val_loss: 0.4080 - val_acc: 0.8052\n",
      "Epoch 283/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3868 - acc: 0.7500\n",
      "Epoch 00283: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4695 - acc: 0.7862 - val_loss: 0.4078 - val_acc: 0.8052\n",
      "Epoch 284/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4067 - acc: 0.8750\n",
      "Epoch 00284: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4694 - acc: 0.7862 - val_loss: 0.4079 - val_acc: 0.8052\n",
      "Epoch 285/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.2934 - acc: 0.8125\n",
      "Epoch 00285: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4692 - acc: 0.7862 - val_loss: 0.4077 - val_acc: 0.8052\n",
      "Epoch 286/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4794 - acc: 0.6250\n",
      "Epoch 00286: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4691 - acc: 0.7862 - val_loss: 0.4076 - val_acc: 0.8052\n",
      "Epoch 287/350\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.4702 - acc: 0.7902\n",
      "Epoch 00287: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4689 - acc: 0.7862 - val_loss: 0.4075 - val_acc: 0.8052\n",
      "Epoch 288/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4098 - acc: 0.8750\n",
      "Epoch 00288: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4688 - acc: 0.7862 - val_loss: 0.4074 - val_acc: 0.8052\n",
      "Epoch 289/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.4913 - acc: 0.7656\n",
      "Epoch 00289: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4687 - acc: 0.7862 - val_loss: 0.4074 - val_acc: 0.8052\n",
      "Epoch 290/350\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4820 - acc: 0.7695\n",
      "Epoch 00290: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4686 - acc: 0.7862 - val_loss: 0.4074 - val_acc: 0.8052\n",
      "Epoch 291/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4836 - acc: 0.6875\n",
      "Epoch 00291: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4685 - acc: 0.7862 - val_loss: 0.4070 - val_acc: 0.8052\n",
      "Epoch 292/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5441 - acc: 0.7500\n",
      "Epoch 00292: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4684 - acc: 0.7862 - val_loss: 0.4069 - val_acc: 0.8052\n",
      "Epoch 293/350\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.4749 - acc: 0.7857\n",
      "Epoch 00293: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4682 - acc: 0.7862 - val_loss: 0.4068 - val_acc: 0.8052\n",
      "Epoch 294/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4161 - acc: 0.7500\n",
      "Epoch 00294: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4681 - acc: 0.7862 - val_loss: 0.4068 - val_acc: 0.8052\n",
      "Epoch 295/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3622 - acc: 0.8125\n",
      "Epoch 00295: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4680 - acc: 0.7862 - val_loss: 0.4068 - val_acc: 0.8052\n",
      "Epoch 296/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.2749 - acc: 0.8750\n",
      "Epoch 00296: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4679 - acc: 0.7862 - val_loss: 0.4067 - val_acc: 0.8052\n",
      "Epoch 297/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4119 - acc: 0.8125\n",
      "Epoch 00297: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4678 - acc: 0.7862 - val_loss: 0.4065 - val_acc: 0.8052\n",
      "Epoch 298/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5959 - acc: 0.8750\n",
      "Epoch 00298: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4677 - acc: 0.7862 - val_loss: 0.4066 - val_acc: 0.8052\n",
      "Epoch 299/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4170 - acc: 0.7500\n",
      "Epoch 00299: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4676 - acc: 0.7862 - val_loss: 0.4065 - val_acc: 0.8052\n",
      "Epoch 300/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4621 - acc: 0.8125\n",
      "Epoch 00300: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4674 - acc: 0.7862 - val_loss: 0.4063 - val_acc: 0.8052\n",
      "Epoch 301/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4575 - acc: 0.8051\n",
      "Epoch 00301: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4673 - acc: 0.7895 - val_loss: 0.4062 - val_acc: 0.8052\n",
      "Epoch 302/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.4858 - acc: 0.7708\n",
      "Epoch 00302: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4672 - acc: 0.7895 - val_loss: 0.4062 - val_acc: 0.8052\n",
      "Epoch 303/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.7996 - acc: 0.7500\n",
      "Epoch 00303: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4671 - acc: 0.7895 - val_loss: 0.4060 - val_acc: 0.8052\n",
      "Epoch 304/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.7612 - acc: 0.5625\n",
      "Epoch 00304: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4670 - acc: 0.7895 - val_loss: 0.4061 - val_acc: 0.8052\n",
      "Epoch 305/350\n",
      " 9/19 [=============>................] - ETA: 0s - loss: 0.4769 - acc: 0.7708\n",
      "Epoch 00305: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4668 - acc: 0.7862 - val_loss: 0.4059 - val_acc: 0.8052\n",
      "Epoch 306/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5432 - acc: 0.5625\n",
      "Epoch 00306: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4668 - acc: 0.7862 - val_loss: 0.4059 - val_acc: 0.8052\n",
      "Epoch 307/350\n",
      " 8/19 [===========>..................] - ETA: 0s - loss: 0.4472 - acc: 0.7969\n",
      "Epoch 00307: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4667 - acc: 0.7895 - val_loss: 0.4056 - val_acc: 0.8052\n",
      "Epoch 308/350\n",
      " 9/19 [=============>................] - ETA: 0s - loss: 0.4286 - acc: 0.8056\n",
      "Epoch 00308: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4665 - acc: 0.7862 - val_loss: 0.4055 - val_acc: 0.8052\n",
      "Epoch 309/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5457 - acc: 0.5625\n",
      "Epoch 00309: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4665 - acc: 0.7862 - val_loss: 0.4057 - val_acc: 0.8052\n",
      "Epoch 310/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6012 - acc: 0.6250\n",
      "Epoch 00310: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4664 - acc: 0.7862 - val_loss: 0.4053 - val_acc: 0.8052\n",
      "Epoch 311/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5298 - acc: 0.8125\n",
      "Epoch 00311: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4662 - acc: 0.7862 - val_loss: 0.4054 - val_acc: 0.8052\n",
      "Epoch 312/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6182 - acc: 0.6875\n",
      "Epoch 00312: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4661 - acc: 0.7862 - val_loss: 0.4053 - val_acc: 0.8052\n",
      "Epoch 313/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3300 - acc: 0.8750\n",
      "Epoch 00313: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4660 - acc: 0.7862 - val_loss: 0.4051 - val_acc: 0.8052\n",
      "Epoch 314/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4681 - acc: 0.7882\n",
      "Epoch 00314: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4659 - acc: 0.7862 - val_loss: 0.4051 - val_acc: 0.8052\n",
      "Epoch 315/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4658 - acc: 0.7862\n",
      "Epoch 00315: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4658 - acc: 0.7862 - val_loss: 0.4050 - val_acc: 0.8052\n",
      "Epoch 316/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4127 - acc: 0.8750\n",
      "Epoch 00316: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4657 - acc: 0.7862 - val_loss: 0.4050 - val_acc: 0.8052\n",
      "Epoch 317/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.2968 - acc: 0.9375\n",
      "Epoch 00317: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4656 - acc: 0.7862 - val_loss: 0.4048 - val_acc: 0.8052\n",
      "Epoch 318/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5340 - acc: 0.7500\n",
      "Epoch 00318: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4654 - acc: 0.7862 - val_loss: 0.4048 - val_acc: 0.8052\n",
      "Epoch 319/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4653 - acc: 0.7862\n",
      "Epoch 00319: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4653 - acc: 0.7862 - val_loss: 0.4047 - val_acc: 0.8052\n",
      "Epoch 320/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.4504 - acc: 0.7917\n",
      "Epoch 00320: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4652 - acc: 0.7862 - val_loss: 0.4047 - val_acc: 0.8052\n",
      "Epoch 321/350\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4655 - acc: 0.7734\n",
      "Epoch 00321: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4651 - acc: 0.7862 - val_loss: 0.4046 - val_acc: 0.8052\n",
      "Epoch 322/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4162 - acc: 0.8125\n",
      "Epoch 00322: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4650 - acc: 0.7862 - val_loss: 0.4045 - val_acc: 0.8052\n",
      "Epoch 323/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.2782 - acc: 0.9375\n",
      "Epoch 00323: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4649 - acc: 0.7862 - val_loss: 0.4046 - val_acc: 0.8052\n",
      "Epoch 324/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.7468 - acc: 0.6875\n",
      "Epoch 00324: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4648 - acc: 0.7862 - val_loss: 0.4044 - val_acc: 0.8052\n",
      "Epoch 325/350\n",
      "12/19 [=================>............] - ETA: 0s - loss: 0.4811 - acc: 0.7812\n",
      "Epoch 00325: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4647 - acc: 0.7862 - val_loss: 0.4043 - val_acc: 0.8052\n",
      "Epoch 326/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4680 - acc: 0.7847\n",
      "Epoch 00326: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4646 - acc: 0.7862 - val_loss: 0.4042 - val_acc: 0.8052\n",
      "Epoch 327/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5090 - acc: 0.8750\n",
      "Epoch 00327: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4645 - acc: 0.7862 - val_loss: 0.4042 - val_acc: 0.8052\n",
      "Epoch 328/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4454 - acc: 0.7978\n",
      "Epoch 00328: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4644 - acc: 0.7862 - val_loss: 0.4040 - val_acc: 0.8052\n",
      "Epoch 329/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5401 - acc: 0.6875\n",
      "Epoch 00329: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4642 - acc: 0.7862 - val_loss: 0.4040 - val_acc: 0.8052\n",
      "Epoch 330/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4734 - acc: 0.7831\n",
      "Epoch 00330: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4642 - acc: 0.7862 - val_loss: 0.4041 - val_acc: 0.8052\n",
      "Epoch 331/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.4665 - acc: 0.8042\n",
      "Epoch 00331: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4641 - acc: 0.7862 - val_loss: 0.4039 - val_acc: 0.8052\n",
      "Epoch 332/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.2998 - acc: 0.8750\n",
      "Epoch 00332: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4640 - acc: 0.7862 - val_loss: 0.4040 - val_acc: 0.8052\n",
      "Epoch 333/350\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.4897 - acc: 0.7708\n",
      "Epoch 00333: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4639 - acc: 0.7862 - val_loss: 0.4040 - val_acc: 0.8052\n",
      "Epoch 334/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4584 - acc: 0.7917\n",
      "Epoch 00334: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4638 - acc: 0.7862 - val_loss: 0.4038 - val_acc: 0.8052\n",
      "Epoch 335/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4804 - acc: 0.7500\n",
      "Epoch 00335: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4637 - acc: 0.7829 - val_loss: 0.4037 - val_acc: 0.8052\n",
      "Epoch 336/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4452 - acc: 0.7500\n",
      "Epoch 00336: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4636 - acc: 0.7829 - val_loss: 0.4036 - val_acc: 0.8052\n",
      "Epoch 337/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5499 - acc: 0.7500\n",
      "Epoch 00337: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4635 - acc: 0.7862 - val_loss: 0.4035 - val_acc: 0.8052\n",
      "Epoch 338/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3656 - acc: 0.8750\n",
      "Epoch 00338: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4634 - acc: 0.7829 - val_loss: 0.4035 - val_acc: 0.8052\n",
      "Epoch 339/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3966 - acc: 0.8125\n",
      "Epoch 00339: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4633 - acc: 0.7829 - val_loss: 0.4035 - val_acc: 0.8052\n",
      "Epoch 340/350\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4676 - acc: 0.7847\n",
      "Epoch 00340: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4632 - acc: 0.7829 - val_loss: 0.4035 - val_acc: 0.8052\n",
      "Epoch 341/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4106 - acc: 0.6875\n",
      "Epoch 00341: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4631 - acc: 0.7829 - val_loss: 0.4033 - val_acc: 0.8052\n",
      "Epoch 342/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5580 - acc: 0.7500\n",
      "Epoch 00342: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4630 - acc: 0.7829 - val_loss: 0.4034 - val_acc: 0.8052\n",
      "Epoch 343/350\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4629 - acc: 0.7829\n",
      "Epoch 00343: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4629 - acc: 0.7829 - val_loss: 0.4033 - val_acc: 0.8052\n",
      "Epoch 344/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5105 - acc: 0.6875\n",
      "Epoch 00344: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4628 - acc: 0.7829 - val_loss: 0.4033 - val_acc: 0.8052\n",
      "Epoch 345/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5682 - acc: 0.6875\n",
      "Epoch 00345: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4627 - acc: 0.7829 - val_loss: 0.4031 - val_acc: 0.8052\n",
      "Epoch 346/350\n",
      "11/19 [================>.............] - ETA: 0s - loss: 0.4940 - acc: 0.7614\n",
      "Epoch 00346: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4626 - acc: 0.7829 - val_loss: 0.4031 - val_acc: 0.8052\n",
      "Epoch 347/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4238 - acc: 0.8750\n",
      "Epoch 00347: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4625 - acc: 0.7862 - val_loss: 0.4030 - val_acc: 0.8052\n",
      "Epoch 348/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3736 - acc: 0.7500\n",
      "Epoch 00348: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4624 - acc: 0.7829 - val_loss: 0.4029 - val_acc: 0.8052\n",
      "Epoch 349/350\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4810 - acc: 0.7647\n",
      "Epoch 00349: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4623 - acc: 0.7829 - val_loss: 0.4029 - val_acc: 0.8052\n",
      "Epoch 350/350\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5632 - acc: 0.6875\n",
      "Epoch 00350: val_acc did not improve from 0.80519\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4623 - acc: 0.7862 - val_loss: 0.4027 - val_acc: 0.8052\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint('diabetes.h5', monitor='val_acc', mode='max', verbose=2, save_best_only=True)\n",
    "history=model.fit(X_train, y_train, batch_size=16, epochs=350, validation_data=(X_test, y_test), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:09:08.314234Z",
     "iopub.status.busy": "2020-11-20T01:09:08.313889Z",
     "iopub.status.idle": "2020-11-20T01:09:08.460744Z",
     "shell.execute_reply": "2020-11-20T01:09:08.459615Z",
     "shell.execute_reply.started": "2020-11-20T01:09:08.314198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 185\n",
      "Trainable params: 185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "present_model = keras.models.load_model('diabetes.h5')\n",
    "present_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:09:08.462680Z",
     "iopub.status.busy": "2020-11-20T01:09:08.462336Z",
     "iopub.status.idle": "2020-11-20T01:09:08.771987Z",
     "shell.execute_reply": "2020-11-20T01:09:08.760945Z",
     "shell.execute_reply.started": "2020-11-20T01:09:08.462645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4183 - acc: 0.8052\n",
      "Accuracy of our model on test data :  80.51947951316833 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model on test data : \" , present_model.evaluate(X_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:09:08.773940Z",
     "iopub.status.busy": "2020-11-20T01:09:08.773632Z",
     "iopub.status.idle": "2020-11-20T01:09:09.116996Z",
     "shell.execute_reply": "2020-11-20T01:09:09.115773Z",
     "shell.execute_reply.started": "2020-11-20T01:09:08.773904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training artifacts\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc','val_acc'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:09:09.118767Z",
     "iopub.status.busy": "2020-11-20T01:09:09.118414Z",
     "iopub.status.idle": "2020-11-20T01:09:09.405210Z",
     "shell.execute_reply": "2020-11-20T01:09:09.404143Z",
     "shell.execute_reply.started": "2020-11-20T01:09:09.118728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training artifacts\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss','val_loss'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Performance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:09:09.406905Z",
     "iopub.status.busy": "2020-11-20T01:09:09.406588Z",
     "iopub.status.idle": "2020-11-20T01:09:09.667964Z",
     "shell.execute_reply": "2020-11-20T01:09:09.655987Z",
     "shell.execute_reply.started": "2020-11-20T01:09:09.406870Z"
    }
   },
   "outputs": [],
   "source": [
    "# predicting on test data.\n",
    "pred_test = present_model.predict(X_test)\n",
    "for i in range (len(pred_test)):\n",
    "    if (pred_test[i] < 0.5):\n",
    "        pred_test[i] = 0\n",
    "    else:\n",
    "        pred_test[i] = 1\n",
    "pred_test = pred_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:09:09.673327Z",
     "iopub.status.busy": "2020-11-20T01:09:09.672810Z",
     "iopub.status.idle": "2020-11-20T01:09:09.681680Z",
     "shell.execute_reply": "2020-11-20T01:09:09.680112Z",
     "shell.execute_reply.started": "2020-11-20T01:09:09.673276Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def view_result(array):\n",
    "    array = np.array(array)\n",
    "    for i in range(len(array)):\n",
    "        if array[i] == 0:\n",
    "            print(\"Not Diabetic\")\n",
    "        else:\n",
    "            print(\"Diabetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:09:09.684100Z",
     "iopub.status.busy": "2020-11-20T01:09:09.683598Z",
     "iopub.status.idle": "2020-11-20T01:09:09.700368Z",
     "shell.execute_reply": "2020-11-20T01:09:09.699241Z",
     "shell.execute_reply.started": "2020-11-20T01:09:09.684059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Diabetic\n",
      "Not Diabetic\n",
      "Not Diabetic\n",
      "Diabetic\n",
      "Not Diabetic\n",
      "Diabetic\n",
      "Not Diabetic\n",
      "Not Diabetic\n",
      "Not Diabetic\n",
      "Diabetic\n"
     ]
    }
   ],
   "source": [
    "view_result(pred_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:09:09.702200Z",
     "iopub.status.busy": "2020-11-20T01:09:09.701894Z",
     "iopub.status.idle": "2020-11-20T01:09:09.720257Z",
     "shell.execute_reply": "2020-11-20T01:09:09.719183Z",
     "shell.execute_reply.started": "2020-11-20T01:09:09.702167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Diabetic\n",
      "Not Diabetic\n",
      "Not Diabetic\n",
      "Diabetic\n",
      "Not Diabetic\n",
      "Diabetic\n",
      "Diabetic\n",
      "Not Diabetic\n",
      "Not Diabetic\n",
      "Diabetic\n"
     ]
    }
   ],
   "source": [
    "view_result(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model with DeepC Compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T01:10:07.539852Z",
     "iopub.status.busy": "2020-11-20T01:10:07.539291Z",
     "iopub.status.idle": "2020-11-20T01:10:18.214008Z",
     "shell.execute_reply": "2020-11-20T01:10:18.213017Z",
     "shell.execute_reply.started": "2020-11-20T01:10:07.539790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading [keras model] from 'diabetes.h5'\n",
      "Saved 'diabetes.onnx'\n",
      "reading onnx model from file  diabetes.onnx\n",
      "Model info:\n",
      "  ir_vesion :  4 \n",
      "  doc       : \n",
      "WARN (ONNX): terminal (input/output) dense_input's shape is less than 1.\n",
      "             changing it to 1.\n",
      "WARN (ONNX): terminal (input/output) dense_3's shape is less than 1.\n",
      "             changing it to 1.\n",
      "WARN (GRAPH): found operator node with the same name (dense_3) as io node.\n",
      "running DNNC graph sanity check ... passed.\n",
      "Writing C++ file  diabetes_deepC/diabetes.cpp\n",
      "INFO (ONNX): model files are ready in dir diabetes_deepC\n",
      "g++ -std=c++11 -O3 -I. -I/opt/tljh/user/lib/python3.7/site-packages/deepC-0.13-py3.7-linux-x86_64.egg/deepC/include -isystem /opt/tljh/user/lib/python3.7/site-packages/deepC-0.13-py3.7-linux-x86_64.egg/deepC/packages/eigen-eigen-323c052e1731 diabetes_deepC/diabetes.cpp -o diabetes_deepC/diabetes.exe\n",
      "Model executable  diabetes_deepC/diabetes.exe\n"
     ]
    }
   ],
   "source": [
    "!deepCC diabetes.h5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
